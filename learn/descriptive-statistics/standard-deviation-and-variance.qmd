---
title: Standard deviation and variance
description: Everything you need to know to learn about standard deviation and variance
---

```{r}
#| echo: false
reticulate::use_virtualenv("../../.venv")
```

```{python}
#| echo: false
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def clean_ax(ax):
   ax.set_xlim(2, 18)
   #ax.set_ylim(0, 0.45)
   ax.spines[["left", "top", "right"]].set_visible(False)
   ax.set_yticks([])
   ax.set_xlabel("Height (in cm)")

np.random.seed(1)

red = "#b20e0e"
blue = "#133ecd"
text_params = dict(x=0, y=0.6, alpha=0.7, size=15, weight="bold")
hist_params = dict(alpha=0.5, bins=15)

sample_size = 200
height_lowvar = np.random.normal(loc=10, scale=1, size=sample_size)
height_highvar = np.random.normal(loc=10, scale=3, size=sample_size)
```

<br>

![](../../img/variance-meme.jpg){width=50% fig-align="center"}

## Measuring dispersion

Imagine you want to measure the <span style="color: #b20e0e; font-weight: bold;">height of plants in your garden</span> because you've seen that they all have __very different heights__, but you don't know how different they are.

You want to compare with <span style="color: #133ecd; font-weight: bold;">your friend's plants</span>, which keeps saying that all of those plants are almost the same height.

In order to do that, we want compare their distribution.

::: {.panel-tabset}

### High variance

```{python}
#| echo: false
fig, ax = plt.subplots()
clean_ax(ax)
ax.hist(height_highvar, color=red, **hist_params)
ax.text(s="Your plants", color=red, transform=ax.transAxes, **text_params)
plt.show()
```

### Low variance

```{python}
#| echo: false
fig, ax = plt.subplots()
clean_ax(ax)
ax.hist(height_lowvar, color=blue, **hist_params)
ax.text(s="Your friend's plants", color=blue, transform=ax.transAxes, **text_params)
plt.show()
```

### Combined

```{python}
#| echo: false
fig, ax = plt.subplots()
clean_ax(ax)
ax.hist(height_highvar, color=red, **hist_params)
ax.hist(height_lowvar, color=blue, **hist_params)
plt.show()
```

:::


Those graphs show us that <span style="color: #b20e0e; font-weight: bold;">your plants</span> height can vary between ~2cm to ~18cm, while <span style="color: #133ecd; font-weight: bold;">your friend's plant</span> are mostly between ~8cm to ~12cm.

The variance and the standard deviation is just a way to __quantify__ this with an actual value.

## How to calculate

Let's assume you have the following measurements for your plants height in cm:

`[10, 15, 4, 22, 25]`

First we need to compute the average:

$$ average = \frac{10 + 15 + 4 + 22 + 25}{5} =  15.2$$

Now that we have the average, we want to compute the __difference between each plant and the average__.

So for example the first plant has an height of `10`, so it gives us: `10 - 15.2 = -5.2`

We do the same with others, and we now have a new list of values: `[-5.2, -0.2, -11.2, 6.8, 9.8]`

As you can see, we have both __some negative and positive values__ here. In order to "fix" it, we take each value and **square it**. For example, we have `-5.2*-5.2 = 27.04`, and so on. Our new list looks like this now:

`[27.04, 0.04, 125.44, 46.24, 96.04]`

The final step to get the variance is to sum up all those values and divide by the number of values (it's basically like calculating an average):

$$ variance = \frac{27.04 + 0.04 + 125.44 + 46.24 + 96.04}{5} =  58.96 $$

And the standard deviation is just the **square root of the variance**:

$$ std = \sqrt{variance} = \sqrt{58.96} \approx 7.68 $$

If we take our example from before about the plant's height, you would have an <span style="color: #b20e0e; font-weight: bold;">higher variance and standard deviation</span> compared to <span style="color: #133ecd; font-weight: bold;">your friend's</span>.

## How to interpret

It's __impossible to interpret__ the variance in itself. This is due to the fact that we squared the values, which changes the original unit of them (e.g it does not make much to interpret squared centimeters).

The main thing we can say about variance is that the higher it is, the more our values tend to be __spreaded__. A contrario, a small variance means that values tend to be pretty close to each other.

For the standard deviation, it's pretty much the same thing, but it's in the __same unit as the original values__ (e.g centimeters).

In __practice__, it becomes interesting to interpret when we know the law followed by our values. For example, if it's normal law, we can use the following:

- About 68% of values fall within 1 standard deviation of the mean.

- About 95% within 2 standard deviations.

- About 99.7% within 3 standard deviations.

For example, if the mean is `10` and the standard deviation `2`, we can say that:

- About 68% of values fall between `8` and `12`.

- About 95% of values fall between `6` and `14`.

- About 99.7% of values fall between `4` and `16`.

## Code examples

::: {.panel-tabset}

### Python

In Python, there is no built-in functions for computing variance or standard deviation. So we have to use the `numpy` package.

It provides both `np.var()` and `np.std()` functions.

```{python}
import numpy as np

heights = [10, 15, 4, 22, 25]

# Variance
np.var(heights)

# Standard deviation
np.std(heights)
```



### R

With R, we can just use the `var()` and `sd()` functions.

```{r}
heights <- c(10, 15, 4, 22, 25)

var(heights)
sd(heights)
```

:::

Have you seen that R and Python don't give the same values here? It's weird right? Well, it's not a bug and it's because they are not calculating the exact same thing.

In Python, numpy computes the **population variance** (what we saw before). A contrario, R is calculating the **sample variance**.

The **sample variance** has for only difference that instead of dividing by the total number of values at the end, it divides by the total number **minus one** (`4` instead of `5` in our previous case).

There is perfectly right mathematical reason behind this, and you can learn more about it [here](https://en.wikipedia.org/wiki/Variance#Population_variance_and_sample_variance). The only thing you have to keep in mind is that the higher the sample size, the more this makes no difference in practice
